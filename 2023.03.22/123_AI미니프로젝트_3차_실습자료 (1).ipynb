{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLojLUpcGNbk"
      },
      "source": [
        "# **차량 공유업체의 차량 파손 여부 분류하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbrllJY8JdkF"
      },
      "source": [
        "## 0.미션\n",
        "\n",
        "* 1) 미션1 : Data Preprocessing\n",
        "    - **과제 수행 목표**\n",
        "        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n",
        "        - 제공된 데이터 : Car_Images.zip\n",
        "            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgdg96jE-mmd"
      },
      "source": [
        "* 2) 미션2 : CNN 모델링\n",
        "    - **과제 수행 목표**\n",
        "        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n",
        "            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n",
        "            - 단, 세부 목차에서 명시한 부분은 지켜주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRrUY4ud_rJV"
      },
      "source": [
        "* 3) 미션3 : Data Argumentation & Transfer Learning\n",
        "    - **과제 수행 목표**\n",
        "        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n",
        "            * Data Augmentation을 적용하세요.(Image Generator)\n",
        "            * Transfer Learning(VGG16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MdjZtxfGNKz"
      },
      "source": [
        "## 1.환경설정 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QgFWzN9xhlr"
      },
      "source": [
        "### (1) 데이터셋 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - C드라이브에 Datasets라는 폴더를 만드세요.\n",
        "        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n",
        "    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elg8NL8vwUs5"
      },
      "source": [
        "* 구글 Colab을 이용하는 경우"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWUbDvBzwiTq",
        "outputId": "1486731b-5ee7-4e03-90f5-7f7f2ad1fce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sVNbCKnLUGc"
      },
      "source": [
        "### (2) 데이터셋 불러오기 \n",
        "- **세부요구사항**\n",
        "    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n",
        "    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n",
        "        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n",
        "    - 폴더구조(로컬)\n",
        "        * C:/Datasets/ : 압축파일\n",
        "        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 폴더구조(구글드라이브브)\n",
        "        * /content/drive/MyDrive/Datasets/ : 압축파일\n",
        "        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n",
        "        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n",
        "        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2-8EaA9x4Xm"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMkstFLKx4Xm"
      },
      "outputs": [],
      "source": [
        "# 압축파일 경로\n",
        "# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n",
        "dataset_path  = '/content/drive/MyDrive/Datasets/'\n",
        "# dataset_path = 'C:/Datasets/'\n",
        "\n",
        "file_path = dataset_path + 'Car_Images.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "ZzwvnkZU3aue",
        "outputId": "ffc7a569-d94e-4a37-b549-3acca93bed74"
      },
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a2013458c137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Datsets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Datsets'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.mkdir('/content/drive/MyDrive/Datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "N6CPQrp-3rin",
        "outputId": "6f7ed0c1-903b-4137-f184-3940039afcca"
      },
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-520af17c258f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Datsets/Car_Images_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Datsets/Car_Images_train'"
          ]
        }
      ],
      "source": [
        "os.mkdir('/content/drive/MyDrive/Datasets/Car_Images_train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgT_RB14Lwza"
      },
      "outputs": [],
      "source": [
        "# 압축 해제\n",
        "data = zipfile.ZipFile(file_path)\n",
        "data.extractall('/content/drive/MyDrive/Datasets/Car_Images_train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hgC0axQyMhI"
      },
      "source": [
        "### (3) 이미지 저장을 위한 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n",
        "        - train\n",
        "            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/ \n",
        "                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n",
        "            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n",
        "                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n",
        "        - val, test 역시 동일한 구조로 생성합니다.\n",
        "    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n",
        "        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc8GnuauOzLf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# 각각 경로 지정\n",
        "# val 과 test 부터 만들어주자\n",
        "folder_path_1 = '/content/drive/MyDrive/Datasets/Car_Images_val'\n",
        "folder_path_2 = '/content/drive/MyDrive/Datasets/Car_Images_test' \n",
        "\n",
        "# train 폴더는 압축을 해제하면서 이미 생성 되어 있습니다.\n",
        "\n",
        "# test 폴더 만들기 os.mkdir()\n",
        "os.mkdir(folder_path_2)\n",
        "\n",
        "\n",
        "# validation 폴더 만들기\n",
        "os.mkdir(folder_path_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi1rldtbrCyc"
      },
      "outputs": [],
      "source": [
        "# train, test, val 폴더에 normal과 abnormal을 만들어주자\n",
        "\n",
        "folder_path_test_norm = '/content/drive/MyDrive/Datasets/Car_Images_test/normal'\n",
        "folder_path_test_abnorm = '/content/drive/MyDrive/Datasets/Car_Images_test/abnormal'\n",
        "\n",
        "folder_path_val_norm = '/content/drive/MyDrive/Datasets/Car_Images_val/normal'\n",
        "folder_path_val_abnorm = '/content/drive/MyDrive/Datasets/Car_Images_val/abnormal'\n",
        "\n",
        "# 생성\n",
        "\n",
        "# os.mkdir(folder_path_train_norm)\n",
        "# os.mkdir(folder_path_train_abnorm)\n",
        "os.mkdir(folder_path_test_norm)\n",
        "os.mkdir(folder_path_test_abnorm)\n",
        "os.mkdir(folder_path_val_norm)\n",
        "os.mkdir(folder_path_val_abnorm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYZKJrP0GtPh"
      },
      "source": [
        "## 2.데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ilpDQfInAE"
      },
      "source": [
        "### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n",
        "- **세부요구사항**\n",
        "    - Training set, Validation set, Test set을 만듭니다.\n",
        "        * size\n",
        "            * test : 전체에서 20%를 추출합니다.\n",
        "            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n",
        "        * 데이터는 랜덤하게 추출해야 합니다.\n",
        "            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n",
        "                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFMSDA26RS-E"
      },
      "source": [
        "#### 1) test, validation 크기를 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhQ_Gu_KNR2g"
      },
      "outputs": [],
      "source": [
        "import random, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4JmGwM2snlx"
      },
      "outputs": [],
      "source": [
        "tr_n_path = '/content/drive/MyDrive/Datasets/Car_Images_train/normal'\n",
        "tr_ab_path = '/content/drive/MyDrive/Datasets/Car_Images_train/abnormal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdU7X9e70dBu",
        "outputId": "85465f36-5385-461e-a0b2-bbb2037f08c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(302, 303)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 전체 이미지 갯수를 확인합니다.\n",
        "len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa2mxylBDVM5",
        "outputId": "722b4372-0c16-4487-9bc7-1aafc60a98e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[60, 61]\n",
            "[48, 48]\n",
            "[194, 194]\n"
          ]
        }
      ],
      "source": [
        "# test 사이즈 : 전체 이미지의 20%\n",
        "te_data_num = [round(len(os.listdir(tr_n_path))*0.2), round(len(os.listdir(tr_ab_path))*0.2)]\n",
        "print(te_data_num)\n",
        "\n",
        "# validation 사이즈 : test를 제외한 나머지 중에서 20%\n",
        "val_data_num = [ round((len(os.listdir(tr_n_path))-te_data_num[0])*0.2) , round((len(os.listdir(tr_n_path))-te_data_num[1])*0.2) ]\n",
        "print(val_data_num)\n",
        "\n",
        "# train 사이즈\n",
        "train_data_num = [len(os.listdir(tr_n_path)) - te_data_num[0] - val_data_num[0],\n",
        "                  len(os.listdir(tr_ab_path))- te_data_num[1] - val_data_num[1]]\n",
        "\n",
        "# 다 나눠준 후 train 사이즈\n",
        "print(train_data_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmRhrViWRXgL"
      },
      "source": [
        "#### 2) test 셋 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmylLe9Ovf9Q"
      },
      "outputs": [],
      "source": [
        "# train_normal에 들어가있는 파일\n",
        "source_list_norm = [f for f in os.listdir(tr_n_path) if os.path.isfile(os.path.join(tr_n_path, f))] # normal 안에 들어가 있는 파일명 리스트\n",
        "source_list_abnorm = [f for f in os.listdir(tr_ab_path) if os.path.isfile(os.path.join(tr_ab_path, f))] # abnormal 안에 들어가 있는 파일명 리스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSwovHr2Fon1"
      },
      "outputs": [],
      "source": [
        "random.seed(2023)\n",
        "\n",
        "train_files_norm = source_list_norm[te_data_num[0]:] # 위에서 알려준 normal의 train_data의 사이즈, [0]은 normal\n",
        "test_files_norm = source_list_norm[:te_data_num[0]] # 위에서 알려준 test_data의 사이즈\n",
        "\n",
        "train_files_abnorm = source_list_abnorm[te_data_num[1]:] # 위에서 알려준 abnormal의 train_data의 사이즈, [1]은 normal\n",
        "test_files_abnorm = source_list_abnorm[:te_data_num[1]] # 위에서 알려준 test_data의 사이즈"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1baoEpMdxrq9"
      },
      "outputs": [],
      "source": [
        "for images in test_files_norm:\n",
        "    source_path = os.path.join(tr_n_path, images)\n",
        "    destination_path = os.path.join(folder_path_test_norm, images)\n",
        "    shutil.copy(source_path, destination_path)\n",
        "\n",
        "# 지금까지 한게 딱 test의 normal만 옮긴 것이다 위 코드들을 함수로 만들어서 바꿔주자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hVsxHdY013C"
      },
      "outputs": [],
      "source": [
        "# test파일에, train abnormal의 20퍼를 저장\n",
        "\n",
        "for images in test_files_abnorm:\n",
        "    source_path = os.path.join(tr_ab_path, images)\n",
        "    destination_path = os.path.join(folder_path_test_abnorm, images)\n",
        "    shutil.copy(source_path, destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AImO1ujiI2IY",
        "outputId": "922fd8d9-b361-4380-f351-3222ba2008fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60, 61)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 추출 후 이미지 갯수 확인\n",
        "len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_test/normal')), len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_test/abnormal')) # 개수 맞는 것 같소.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V4mh3hxRpR2"
      },
      "source": [
        "#### 3) validation 셋 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXYmEdCjAEDu"
      },
      "outputs": [],
      "source": [
        "# train_normal에 들어가있는 파일\n",
        "random.seed(2023)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5fSowYV91Kh"
      },
      "outputs": [],
      "source": [
        "# test_files_norm에 있는 원소들을 제외시켜줘야 한다\n",
        "# norm\n",
        "# abnorm\n",
        "source_list_norm = [item for item in source_list_norm if item not in test_files_norm]\n",
        "source_list_abnorm = [item for item in source_list_abnorm if item not in test_files_abnorm]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "menWVVPf5Izx",
        "outputId": "02f32320-8096-490a-8c23-a9b99732a6db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(242, 242)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(source_list_norm), len(source_list_abnorm) # train에서 test를 제해준 사이즈는 맞다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uunt0rQM-VJT"
      },
      "outputs": [],
      "source": [
        "train_files_norm = source_list_norm[val_data_num[0]:] # 위에서 알려준 normal의 train_data의 사이즈, [0]은 normal\n",
        "val_files_norm = source_list_norm[:val_data_num[0]] # 위에서 알려준 test_data의 사이즈\n",
        "\n",
        "train_files_abnorm = source_list_abnorm[val_data_num[1]:] # 위에서 알려준 abnormal의 train_data의 사이즈, [1]은 normal\n",
        "val_files_abnorm = source_list_abnorm[:val_data_num[1]] # 위에서 알려준 test_data의 사이즈"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPIuS5kO--7s"
      },
      "outputs": [],
      "source": [
        "# validation normal 뽑기\n",
        "for images in val_files_norm:\n",
        "    source_path = os.path.join(tr_n_path, images)\n",
        "    destination_path = os.path.join(folder_path_val_norm, images)\n",
        "    shutil.copy(source_path, destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5QKm5SB_GUQ"
      },
      "outputs": [],
      "source": [
        "# validation abnormal 뽑기\n",
        "for images in val_files_abnorm:\n",
        "    source_path = os.path.join(tr_ab_path, images)\n",
        "    destination_path = os.path.join(folder_path_val_abnorm, images)\n",
        "    shutil.copy(source_path, destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvQvZ5jpIWLr",
        "outputId": "7d44a96d-63f3-41c6-b528-5d9748717ec0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(242, 242)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(source_list_norm), len(source_list_abnorm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIT85iSdM4U-",
        "outputId": "66f35719-c80c-4a52-fe0b-96bd8d5c2ff1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48, 48)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 추출 후 이미지 갯수 확인\n",
        "\n",
        "\n",
        "len(os.listdir(folder_path_val_norm)), len(os.listdir(folder_path_val_abnorm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umkazJbYJK4m",
        "outputId": "36ccacac-12ee-4a21-e9dd-a58a25bc3a0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(302, 303)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir(tr_n_path)), len(os.listdir(tr_ab_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiYmjO5ZFRft"
      },
      "outputs": [],
      "source": [
        "# 마지막으로 옮겨준 test_normal, test_abnormal, val_normal, val_abnormal을 train 파일에서 없애줘야 한다\n",
        "\n",
        "# 1. test_normal\n",
        "\n",
        "for images in test_files_norm:\n",
        "    # images는 파일명이 들어가있다\n",
        "    # file_path안에 tr_n_path속 images를 결합시켜 없애주도록하자\n",
        "    file_path = os.path.join(tr_n_path, images)\n",
        "    os.remove(file_path)\n",
        "\n",
        "for images in test_files_abnorm:\n",
        "    file_path = os.path.join(tr_ab_path, images)\n",
        "    os.remove(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB3NFNDzHUCf"
      },
      "outputs": [],
      "source": [
        "# validation 없애기\n",
        "    \n",
        "for images in val_files_norm:\n",
        "    file_path = os.path.join(tr_n_path, images)\n",
        "    os.remove(file_path)\n",
        "\n",
        "for images in val_files_abnorm:\n",
        "    file_path = os.path.join(tr_ab_path, images)\n",
        "    os.remove(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkvKmYw-I4Sz",
        "outputId": "fd15c543-076d-45a7-f2a8-2d2ca280fc53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(194, 194)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir(tr_n_path)), len(os.listdir(tr_ab_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSO004sgyyu"
      },
      "source": [
        "### (2) 데이터 복사 및 이동\n",
        "- **세부요구사항**\n",
        "    - 분할된 데이터를 복사 이동합니다.\n",
        "        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n",
        "        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n",
        "    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n",
        "        - 새로운 폴더 명\n",
        "            * copy_images/trainset\n",
        "            * copy_images/validset\n",
        "            * copy_images/testset\n",
        "        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다. \n",
        "            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n",
        "        - os, shutil 모듈을 활용하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UbNfTY4kOSZ"
      },
      "source": [
        "#### 1) abnormal 파일 복사"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhkKqLfTkjGI"
      },
      "source": [
        "* 복사하기 : shutil.copytree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wha6U9pQM2ou"
      },
      "outputs": [],
      "source": [
        "from distutils.dir_util import copy_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTMVxJJJya98"
      },
      "outputs": [],
      "source": [
        "# \n",
        "shutil.copytree('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal', '/content/drive/MyDrive/Datasets/copy_images/trainset')\n",
        "copy_tree('/content/drive/MyDrive/Datasets/Car_Images_train/normal', '/content/drive/MyDrive/Datasets/copy_images/trainset')\n",
        "\n",
        "shutil.copytree('/content/drive/MyDrive/Datasets/Car_Images_val/abnormal', '/content/drive/MyDrive/Datasets/copy_images/validset')\n",
        "copy_tree('/content/drive/MyDrive/Datasets/Car_Images_val/normal', '/content/drive/MyDrive/Datasets/copy_images/validset')\n",
        "\n",
        "shutil.copytree('/content/drive/MyDrive/Datasets/Car_Images_test/abnormal', '/content/drive/MyDrive/Datasets/copy_images/testset')\n",
        "copy_tree('/content/drive/MyDrive/Datasets/Car_Images_test/normal', '/content/drive/MyDrive/Datasets/copy_images/testset')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU0T-ypHkV6D"
      },
      "source": [
        "* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv6gafRyz6ul"
      },
      "outputs": [],
      "source": [
        "file_dir_path = '/content/drive/MyDrive/Datasets/copy_images/trainset'\n",
        "file_list = os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal')\n",
        "# train set에서의 abnormal, 위치는 copy_images/trainset이다\n",
        "for file in file_list:\n",
        "    original_path = os.path.join(file_dir_path, file)\n",
        "    new_name = 'ab_' + file\n",
        "    new_path = os.path.join(file_dir_path, new_name)\n",
        "    os.rename(original_path, new_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoYN3nloV2ft"
      },
      "outputs": [],
      "source": [
        "file_dir_path = '/content/drive/MyDrive/Datasets/copy_images/validset'\n",
        "file_list = os.listdir('/content/drive/MyDrive/Datasets/Car_Images_val/abnormal')\n",
        "# valid set에서의 abnormal, 위치는 copy_images/validset이다\n",
        "for file in file_list:\n",
        "    original_path = os.path.join(file_dir_path, file)\n",
        "    new_name = 'ab_' + file\n",
        "    new_path = os.path.join(file_dir_path, new_name)\n",
        "    os.rename(original_path, new_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5-wDqJwYCiU"
      },
      "outputs": [],
      "source": [
        "file_dir_path = '/content/drive/MyDrive/Datasets/copy_images/testset'\n",
        "file_list = os.listdir('/content/drive/MyDrive/Datasets/Car_Images_test/abnormal')\n",
        "# test set에서의 abnormal, 위치는 copy_images/testset이다\n",
        "for file in file_list:\n",
        "    original_path = os.path.join(file_dir_path, file)\n",
        "    new_name = 'ab_' + file\n",
        "    new_path = os.path.join(file_dir_path, new_name)\n",
        "    os.rename(original_path, new_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk6xITmTksyK"
      },
      "source": [
        "#### 2) normal 파일 복사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw3DmdTS17RM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzEXHZrqkz88"
      },
      "source": [
        "* 데이터 갯수 조회"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugNprP9d-Gti",
        "outputId": "5f5f431b-297d-4277-db36-ea80e4740e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "388\n",
            "96\n",
            "121\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir(dataset_path+'copy_images/trainset/')))\n",
        "print(len(os.listdir(dataset_path+'copy_images/validset/')))\n",
        "print(len(os.listdir(dataset_path+'copy_images/testset/')))\n",
        "\n",
        "# 오늘까지 해야하는 작업."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfYDW1Pj7ZdU"
      },
      "source": [
        "## 3.모델링 I\n",
        "* **세부요구사항**\n",
        "    * 모델링을 위한 데이터 구조 만들기\n",
        "        * x : 이미지를 array로 변환합니다.\n",
        "        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n",
        "    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n",
        "        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n",
        "        * Early Stopping을 반드시 사용하세요.\n",
        "            * 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "Rg553KIvxE6W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIfqg6e0xE6A"
      },
      "source": [
        "### (1) X : image to array\n",
        "- **세부요구사항**\n",
        "    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n",
        "    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n",
        "    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n",
        "        * 각 폴더로 부터 이미지 목록을 만들고\n",
        "        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n",
        "            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n",
        "            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n",
        "            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n",
        "        * 데이터셋에 추가합니다.(데이터셋도 array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FovkIeSDT367"
      },
      "source": [
        "#### 1) 이미지 목록 만들기\n",
        "* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X022f0QMxE6W"
      },
      "outputs": [],
      "source": [
        "# 이미지 목록 저장\n",
        "img_train_list = os.listdir('/content/drive/MyDrive/Datasets/copy_images/trainset')\n",
        "img_valid_list = os.listdir('/content/drive/MyDrive/Datasets/copy_images/validset')\n",
        "img_test_list = os.listdir('/content/drive/MyDrive/Datasets/copy_images/testset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlCFDPadbqZL"
      },
      "outputs": [],
      "source": [
        "ab_train = [image for image in img_train_list if image.startswith('ab_')]\n",
        "ab_val = [image for image in img_valid_list if image.startswith('ab_')]\n",
        "ab_test = [image for image in img_test_list if image.startswith('ab_')]\n",
        "\n",
        "norm_train = [image for image in img_train_list if image not in ab_train]\n",
        "norm_val = [image for image in img_valid_list if image not in ab_val]\n",
        "norm_test = [image for image in img_test_list if image not in ab_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgvW_LQfxE6X"
      },
      "outputs": [],
      "source": [
        "# 메모리, 처리시간을 위해서 이미지 크기 조정\n",
        "img_size = 280 ## 사이즈 조정 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSt88mjPV33u"
      },
      "source": [
        "#### 2) 이미지들을 배열 데이터셋으로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhEdBiKfxE6Y",
        "outputId": "2e156a84-ed86-436f-9e72-976a6a662bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXFQz37Az4ul",
        "outputId": "ff73a0f4-837e-496b-c60a-b97eef874644"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "388"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(img_train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3rERGXX2j4u"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# train데이터의 abnormal 부터 담아주자\n",
        "\n",
        "for file in img_train_list:\n",
        "    # file은 img_train_list속 normal과 ab이 섞여있는 파일명의 리스트이다.\n",
        "    file_path = os.path.join('/content/drive/MyDrive/Datasets/copy_images/trainset', file)\n",
        "    if file.startswith('ab_'):\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((img_size, img_size))\n",
        "        img_array = np.array(img)\n",
        "        x_train.append(img_array)\n",
        "        y_train.append(0)\n",
        "\n",
        "    else:\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((img_size, img_size))\n",
        "        img_array = np.array(img)\n",
        "        x_train.append(img_array)\n",
        "        y_train.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diAvfkYG4hVT"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybp_LcyZ5VVA",
        "outputId": "fc849c69-17d9-4c90-ac14-107506090a24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((382, 280, 280, 3), (382,))"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWVjDaKg5S7F"
      },
      "outputs": [],
      "source": [
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "# train데이터의 abnormal 부터 담아주자\n",
        "\n",
        "for file in img_valid_list:\n",
        "    # file은 img_train_list속 normal과 ab이 섞여있는 파일명의 리스트이다.\n",
        "    file_path = os.path.join('/content/drive/MyDrive/Datasets/copy_images/validset', file)\n",
        "    if file.startswith('ab_'):\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((img_size, img_size))\n",
        "        img_array = np.array(img)\n",
        "        x_val.append(img_array)\n",
        "        y_val.append(0)\n",
        "\n",
        "    else:\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((img_size, img_size))\n",
        "        img_array = np.array(img)\n",
        "        x_val.append(img_array)\n",
        "        y_val.append(1)\n",
        "\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHV1ytzr5tSY",
        "outputId": "3dbcf022-9cc2-4766-c455-6b5da49bb685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((96, 280, 280, 3), (96,))"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmnPimBa5TU6"
      },
      "outputs": [],
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "# train데이터의 abnormal 부터 담아주자\n",
        "\n",
        "for file in img_test_list:\n",
        "    # file은 img_train_list속 normal과 ab이 섞여있는 파일명의 리스트이다.\n",
        "    file_path = os.path.join('/content/drive/MyDrive/Datasets/copy_images/testset', file)\n",
        "    if file.startswith('ab_'):\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((img_size, img_size))\n",
        "        img_array = np.array(img)\n",
        "        x_test.append(img_array)\n",
        "        y_test.append(0)\n",
        "\n",
        "    else:\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((img_size, img_size))\n",
        "        img_array = np.array(img)\n",
        "        x_test.append(img_array)\n",
        "        y_test.append(1)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTnWax3M5TjN",
        "outputId": "bb4c631c-8bca-46f0-fe97-023af97a2c1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((121, 280, 280, 3), (121,))"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yTj4Caw0pFN",
        "outputId": "b0cf4b18-e9f5-4154-f05b-6e4295c36295"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "382"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(img_train_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doUM37LxxE6Z"
      },
      "source": [
        "### (2) y : 클래스 만들기\n",
        "- **세부요구사항**\n",
        "    - Training set / Validation set / Test set의 y를 생성합니다.\n",
        "        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n",
        "        - normal을 0, abnormal을 1로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nl1Uv9UxE6b",
        "outputId": "2a60a769-ec31-4bcd-edc6-1576154dfd64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "388\n",
            "194\n",
            "---\n",
            "96\n",
            "48\n",
            "---\n",
            "121\n",
            "61\n"
          ]
        }
      ],
      "source": [
        "# 데이터 갯수 확인\n",
        "print( len(img_train_list) )\n",
        "print( len([val for val in img_train_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_valid_list) )\n",
        "print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_test_list) )\n",
        "print( len([val for val in img_test_list if val.startswith('ab_')]) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfaCLlNn04C"
      },
      "source": [
        "* y_train, y_valid, y_test 만들기\n",
        "    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVrPQdhTxE6b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z586wXFu7ZgT"
      },
      "source": [
        "### (3) 모델1\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIvIO6RKa0mp"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TtIIz6XJQ5E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHM91_bha3Kc"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "OHnFVZuKa42f"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor = 'val_loss',\n",
        "                   min_delta = 0,\n",
        "                   patience = 5,\n",
        "                   verbose = 0,\n",
        "                   restore_best_weights = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnrTSupKa42f",
        "outputId": "ddfe0922-5592-43b2-90f5-eb5ee6edde5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 280, 280, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 280, 280, 32)      9248      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 280, 280, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 140, 140, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 140, 140, 32)      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 140, 140, 64)      18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 140, 140, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 140, 140, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 70, 70, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 70, 70, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 313600)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              321127424 \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321,198,497\n",
            "Trainable params: 321,196,257\n",
            "Non-trainable params: 2,240\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "#     0. Functional, Sequential 중 택일\n",
        "\n",
        "#     1. 인풋레이어\n",
        "il = keras.layers.Input(shape = (280,280, 3))\n",
        "#     2. Convolution : 필터수 32개, 사이즈(3, 3), same padding\n",
        "cl = keras.layers.Conv2D(filters = 32,\n",
        "                         kernel_size = (3,3),\n",
        "                         strides = (1,1),\n",
        "                         padding = 'same',\n",
        "                         activation = 'relu')(il)\n",
        "#     3. Convolution : 필터수 32개, 사이즈(3, 3), same padding\n",
        "cl = keras.layers.Conv2D(filters = 32,\n",
        "                         kernel_size = (3,3),\n",
        "                         padding = 'same',\n",
        "                         activation = 'relu')(cl)\n",
        "#     4. BatchNormalization\n",
        "bl = keras.layers.BatchNormalization()(cl)\n",
        "#     5. MaxPooling : 사이즈(2,2) 스트라이드(2,2)\n",
        "ml = keras.layers.MaxPool2D(pool_size = (2,2))(bl)\n",
        "#     6. DropOut : 25% 비활성화\n",
        "dl = keras.layers.Dropout(rate = 0.25)(ml)\n",
        "#     7. Convolution : 필터수 64개, 사이즈(3, 3), same padding\n",
        "cl = keras.layers.Conv2D(filters = 64,\n",
        "                         kernel_size = (3,3),\n",
        "                         padding = 'same',\n",
        "                         activation = 'relu')(dl)\n",
        "#     8. Convolution : 필터수 64개, 사이즈(3, 3), same padding\n",
        "cl = keras.layers.Conv2D(filters = 64,\n",
        "                         kernel_size = (3,3),\n",
        "                         padding = 'same',\n",
        "                         activation = 'relu')(cl)\n",
        "#     9. BatchNormalization\n",
        "bl = keras.layers.BatchNormalization()(cl)\n",
        "#     10. MaxPooling : 사이즈(2,2) 스트라이드(2,2)\n",
        "ml = keras.layers.MaxPool2D(pool_size = (2,2))(bl)\n",
        "#     11. DropOut : 25% 비활성화\n",
        "dl = keras.layers.Dropout(0.25)(ml)\n",
        "#     12. Flatten( )\n",
        "fl = keras.layers.Flatten()(dl)\n",
        "#     13. Fully Connected Layer : 노드 1024개\n",
        "hl = keras.layers.Dense(1024, activation = 'relu')(fl)\n",
        "#     14. BatchNormalization\n",
        "bl = keras.layers.BatchNormalization()(hl)\n",
        "#     15. DropOut : 35% 비활성화\n",
        "dl = keras.layers.Dropout(0.35)(bl)\n",
        "#     16. 아웃풋레이어\n",
        "ol = keras.layers.Dense(1, activation = 'sigmoid')(dl)\n",
        "\n",
        "model = keras.models.Model(il,ol)\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zage6-Z0a6DX"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "NlbvwBrgCHA5"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuiKJWj7vRH_",
        "outputId": "4de8dc0b-933d-45c9-fe53-8295c04e7a15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8076"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "rand_n = np.random.randint(0, 10000)\n",
        "rand_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "cfHmHnukB6np"
      },
      "outputs": [],
      "source": [
        "x_train = shuffle(x_train, random_state = rand_n)\n",
        "y_train = shuffle(y_train, random_state = rand_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpuzB4g-raOh",
        "outputId": "00d5d9ca-9392-42fd-c3aa-4c6ed0917077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xkFFlFdbBZb",
        "outputId": "4cf70334-f327-48ee-d218-31081c06b735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "13/13 [==============================] - 32s 930ms/step - loss: 1.4343 - accuracy: 0.7912 - val_loss: 78.4681 - val_accuracy: 0.5000\n",
            "Epoch 2/10000\n",
            "13/13 [==============================] - 4s 332ms/step - loss: 0.7184 - accuracy: 0.8454 - val_loss: 102.9556 - val_accuracy: 0.5000\n",
            "Epoch 3/10000\n",
            "13/13 [==============================] - 10s 816ms/step - loss: 0.2208 - accuracy: 0.9253 - val_loss: 5.8234 - val_accuracy: 0.5000\n",
            "Epoch 4/10000\n",
            "13/13 [==============================] - 4s 343ms/step - loss: 0.1566 - accuracy: 0.9278 - val_loss: 6.7349 - val_accuracy: 0.5000\n",
            "Epoch 5/10000\n",
            "13/13 [==============================] - 7s 541ms/step - loss: 0.0842 - accuracy: 0.9768 - val_loss: 0.6846 - val_accuracy: 0.6771\n",
            "Epoch 6/10000\n",
            "13/13 [==============================] - 4s 337ms/step - loss: 0.0840 - accuracy: 0.9716 - val_loss: 1.5121 - val_accuracy: 0.5312\n",
            "Epoch 7/10000\n",
            "13/13 [==============================] - 4s 335ms/step - loss: 0.0365 - accuracy: 0.9948 - val_loss: 0.9981 - val_accuracy: 0.6042\n",
            "Epoch 8/10000\n",
            "13/13 [==============================] - 6s 497ms/step - loss: 0.0438 - accuracy: 0.9923 - val_loss: 0.6199 - val_accuracy: 0.7292\n",
            "Epoch 9/10000\n",
            "13/13 [==============================] - 6s 463ms/step - loss: 0.0240 - accuracy: 0.9974 - val_loss: 0.4384 - val_accuracy: 0.8438\n",
            "Epoch 10/10000\n",
            "13/13 [==============================] - 4s 331ms/step - loss: 0.0241 - accuracy: 0.9948 - val_loss: 0.8705 - val_accuracy: 0.6354\n",
            "Epoch 11/10000\n",
            "13/13 [==============================] - 4s 330ms/step - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.6788 - val_accuracy: 0.6979\n",
            "Epoch 12/10000\n",
            "13/13 [==============================] - 4s 328ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 0.7396\n",
            "Epoch 13/10000\n",
            "13/13 [==============================] - 4s 329ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.7434 - val_accuracy: 0.6979\n",
            "Epoch 14/10000\n",
            "13/13 [==============================] - 4s 331ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.6875\n",
            "Epoch 15/10000\n",
            "13/13 [==============================] - 4s 331ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.8422 - val_accuracy: 0.6562\n",
            "Epoch 16/10000\n",
            "13/13 [==============================] - 4s 329ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.7210 - val_accuracy: 0.5521\n",
            "Epoch 17/10000\n",
            "13/13 [==============================] - 4s 329ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.8125\n",
            "Epoch 18/10000\n",
            "13/13 [==============================] - 4s 329ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.6037 - val_accuracy: 0.7396\n",
            "Epoch 19/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 9.\n",
            "13/13 [==============================] - 6s 431ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.7188\n",
            "Epoch 19: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7bab26de80>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs = 10000, verbose = 1, callbacks = [es], validation_data = (x_val,y_val))\n",
        "\n",
        "# accuracy와 val_accuracy가 유지 되는 것은 어마무시한 overfitting이 일어나고 있다고 한다.\n",
        "# stackoverflow에서는 data augmentation이나 더 작은 network를 만들어보라고 말하고 있다.\n",
        "# Data Agumentation 어케 하지?\n",
        "# 위에 있는 랜덤 인자를 넣어줘서 좀 더 숫자를 무작위로 섞은 결과, 좀 보기 좋은 결과가 나왔다\n",
        "# 하지만 accuracy는 이상하게 높아지고 있는데, val_accuracy가 높아지지 않는 것을 보면 똑같이 overfitting이 일어나고 있는 것 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-EQFVkCbBZc",
        "outputId": "bae1d5d8-efb6-42f7-e15a-e081252dbdb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 331ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdtFwtWVwQC9",
        "outputId": "cdbeca16-fa3b-40de-ded6-a7db4280378a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0.01140201],\n",
              "        [0.00194263],\n",
              "        [0.02028764],\n",
              "        [0.9969703 ],\n",
              "        [0.7470803 ]], dtype=float32), array([0, 0, 0, 0, 0]))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred[:5], y_test[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxqTMb6aAyqL"
      },
      "outputs": [],
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mz2JHUd_dMW",
        "outputId": "c8d81668-9f98-4950-f561-f94461d14c07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7605633802816902"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_pred, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRoacK2mcLPb"
      },
      "source": [
        "### (4) 모델2\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오.\n",
        "\n",
        "\n",
        "- **1. overfitting을 줄이자 1번, 적은 데이터에 알맞은 model 사용**\n",
        "    - 이 경우 EfficientNet을 사용해보도록 하자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WTwG8NFoLBQ"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRmG-o7f9PO8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "\n",
        "# # 나는 EfficientNetB0을 pretrained model로 가져올게요\n",
        "# base_model = efficientnet.EfficientNetB0(include_top = True, # 그림으로 보면 주로 아래로 쌓이는데 왜 include top일까?\n",
        "#                                                               # tensorflow 공식문서 include_top에 대해서는 이렇게 설명 되어있다.\n",
        "#                                                               # top에 fully connected layer가 있는 경우 \n",
        "#                                          weights ='imagenet', \n",
        "#                                          input_shape = (224, 224, 3))\n",
        "\n",
        "# # pretrained 된 모델 (output 빼고) freeze -> 가중치 가져오겠단 말\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # 시작과 끝 엮기\n",
        "# # 여기서 뭣모르고 input을 il했다가는 pretrained 다 날리고 layer 층 5개만 쌓인다.\n",
        "# model = models.Model(base_model.input, base_model.output)\n",
        "\n",
        "# # Compile the model\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHu5gey1oLBR",
        "outputId": "6946d554-c717-4ea0-83d0-856a74ef8112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 2s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 280, 280, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 280, 280, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 280, 280, 3)  7           ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " rescaling_1 (Rescaling)        (None, 280, 280, 3)  0           ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, 281, 281, 3)  0           ['rescaling_1[0][0]']            \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 140, 140, 32  864         ['stem_conv_pad[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 140, 140, 32  128         ['stem_conv[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 140, 140, 32  0           ['stem_bn[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, 140, 140, 32  288        ['stem_activation[0][0]']        \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, 140, 140, 32  128        ['block1a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, 140, 140, 32  0          ['block1a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, 140, 140, 32  0           ['block1a_activation[0][0]',     \n",
            "                                )                                 'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 140, 140, 16  512         ['block1a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 140, 140, 16  64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 140, 140, 96  1536        ['block1a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 140, 140, 96  384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 140, 140, 96  0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, 141, 141, 96  0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           )                                ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, 70, 70, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, 70, 70, 96)  384         ['block2a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, 70, 70, 96)  0           ['block2a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, 70, 70, 96)   0           ['block2a_activation[0][0]',     \n",
            "                                                                  'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 70, 70, 24)   2304        ['block2a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 70, 70, 24)  96          ['block2a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 70, 70, 144)  3456        ['block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 70, 70, 144)  576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 70, 70, 144)  0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, 70, 70, 144)  1296       ['block2b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, 70, 70, 144)  576        ['block2b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, 70, 70, 144)  0          ['block2b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, 70, 70, 144)  0           ['block2b_activation[0][0]',     \n",
            "                                                                  'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 70, 70, 24)   3456        ['block2b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 70, 70, 24)  96          ['block2b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 70, 70, 24)   0           ['block2b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 70, 70, 24)   0           ['block2b_drop[0][0]',           \n",
            "                                                                  'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 70, 70, 144)  3456        ['block2b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 70, 70, 144)  576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 70, 70, 144)  0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, 73, 73, 144)  0          ['block3a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, 35, 35, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, 35, 35, 144)  576        ['block3a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, 35, 35, 144)  0          ['block3a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, 35, 35, 144)  0           ['block3a_activation[0][0]',     \n",
            "                                                                  'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 35, 35, 40)   5760        ['block3a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 35, 35, 40)  160         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 35, 35, 240)  9600        ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 35, 35, 240)  960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 35, 35, 240)  0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, 35, 35, 240)  6000       ['block3b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, 35, 35, 240)  960        ['block3b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, 35, 35, 240)  0          ['block3b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, 35, 35, 240)  0           ['block3b_activation[0][0]',     \n",
            "                                                                  'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 35, 35, 40)   9600        ['block3b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 35, 35, 40)  160         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 35, 35, 40)   0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 35, 35, 40)   0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 35, 35, 240)  9600        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 35, 35, 240)  960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 35, 35, 240)  0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, 37, 37, 240)  0          ['block4a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, 18, 18, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 18, 18, 240)  960        ['block4a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 18, 18, 240)  0          ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 18, 18, 240)  0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 18, 18, 80)   19200       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 18, 18, 80)  320         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 18, 18, 480)  38400       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 18, 18, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 18, 18, 480)  0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, 18, 18, 480)  4320       ['block4b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 18, 18, 480)  1920       ['block4b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 18, 18, 480)  0          ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 18, 18, 480)  0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 18, 18, 80)   38400       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 18, 18, 80)  320         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 18, 18, 80)   0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 18, 18, 80)   0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 18, 18, 480)  38400       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 18, 18, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 18, 18, 480)  0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, 18, 18, 480)  4320       ['block4c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 18, 18, 480)  1920       ['block4c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 18, 18, 480)  0          ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 18, 18, 480)  0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 18, 18, 80)   38400       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 18, 18, 80)  320         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 18, 18, 80)   0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 18, 18, 80)   0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 18, 18, 480)  38400       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 18, 18, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 18, 18, 480)  0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, 18, 18, 480)  12000      ['block5a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 18, 18, 480)  1920       ['block5a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 18, 18, 480)  0          ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 18, 18, 480)  0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 18, 18, 112)  53760       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 18, 18, 112)  448        ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 18, 18, 672)  75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 18, 18, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 18, 18, 672)  0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, 18, 18, 672)  16800      ['block5b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 18, 18, 672)  2688       ['block5b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 18, 18, 672)  0          ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 18, 18, 672)  0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 18, 18, 112)  75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 18, 18, 112)  448        ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 18, 18, 112)  0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 18, 18, 112)  0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 18, 18, 672)  75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 18, 18, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 18, 18, 672)  0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, 18, 18, 672)  16800      ['block5c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 18, 18, 672)  2688       ['block5c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 18, 18, 672)  0          ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 18, 18, 672)  0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 18, 18, 112)  75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 18, 18, 112)  448        ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 18, 18, 112)  0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 18, 18, 112)  0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 18, 18, 672)  75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 18, 18, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 18, 18, 672)  0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, 21, 21, 672)  0          ['block6a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, 9, 9, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 9, 9, 672)   2688        ['block6a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 9, 9, 672)   0           ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 9, 9, 672)    0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 9, 9, 192)    129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 9, 9, 192)   768         ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 9, 9, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 9, 9, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 9, 9, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, 9, 9, 1152)  28800       ['block6b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 9, 9, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 9, 9, 1152)  0           ['block6b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 9, 9, 1152)   0           ['block6b_activation[0][0]',     \n",
            "                                                                  'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 9, 9, 192)    221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 9, 9, 192)   768         ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 9, 9, 192)    0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 9, 9, 192)    0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 9, 9, 1152)   221184      ['block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 9, 9, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 9, 9, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, 9, 9, 1152)  28800       ['block6c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 9, 9, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 9, 9, 1152)  0           ['block6c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 9, 9, 1152)   0           ['block6c_activation[0][0]',     \n",
            "                                                                  'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 9, 9, 192)    221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 9, 9, 192)   768         ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 9, 9, 192)    0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 9, 9, 192)    0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 9, 9, 1152)   221184      ['block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 9, 9, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 9, 9, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, 9, 9, 1152)  28800       ['block6d_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 9, 9, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 9, 9, 1152)  0           ['block6d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 9, 9, 1152)   0           ['block6d_activation[0][0]',     \n",
            "                                                                  'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 9, 9, 192)    221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 9, 9, 192)   768         ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 9, 9, 192)    0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 9, 9, 192)    0           ['block6d_drop[0][0]',           \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, 9, 9, 1152)   221184      ['block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, 9, 9, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, 9, 9, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, 9, 9, 1152)  10368       ['block7a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, 9, 9, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, 9, 9, 1152)  0           ['block7a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, 9, 9, 1152)   0           ['block7a_activation[0][0]',     \n",
            "                                                                  'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, 9, 9, 320)    368640      ['block7a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, 9, 9, 320)   1280        ['block7a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 9, 9, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 9, 9, 1280)   5120        ['top_conv[0][0]']               \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 9, 9, 1280)   0           ['top_bn[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['top_activation[0][0]']         \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          163968      ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            129         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,213,668\n",
            "Trainable params: 164,097\n",
            "Non-trainable params: 4,049,571\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 나는 EfficientNetB0을 pretrained model로 가져올게요\n",
        "base_model = efficientnet.EfficientNetB0(include_top = False, # 그림으로 보면 주로 아래로 쌓이는데 왜 include top일까? \n",
        "                                         weights ='imagenet', # imagenet 바탕으로 미리 학습된 것 (include_top을 True로 해줬을 때, \n",
        "                                                              # 마지막 레이어가 1000으로 나누어준다는 사실을 알 수 있다.)\n",
        "                                         input_shape = (280, 280, 3))\n",
        "\n",
        "# pretrained 된 모델 (output 빼고) freeze -> 가중치 가져오겠단 말\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Functional API를 이용한 엮기\n",
        "il = base_model.output\n",
        "cl = layers.GlobalAveragePooling2D()(il)\n",
        "hl = layers.Dense(128, activation='relu')(cl)\n",
        "hl = layers.Dropout(0.5)(hl)\n",
        "ol = layers.Dense(1, activation='sigmoid')(hl)\n",
        "\n",
        "# 시작과 끝 엮기\n",
        "# 여기서 뭣모르고 input을 il했다가는 pretrained 다 날리고 layer 층 5개만 쌓인다.\n",
        "# 반드시 inputs = base_model.input\n",
        "model = models.Model(base_model.input, ol)\n",
        "\n",
        "# 컴파일\n",
        "model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 요약\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqPQ40Jf5DDr",
        "outputId": "26f1866b-5fe1-47f1-d124-9b2ee949d972"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "242"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.layers)\n",
        "\n",
        "# 242개의 층으로 되어있다는 것을 확인할 수 있었다\n",
        "# 결과가 좋지 않다면 마지막 한 30, 50개 정도의 layers의 가중치는 버리고 다시 해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqTzgRTroLBR"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEXSzSr15Z7J",
        "outputId": "7c9479a2-af93-49bb-9492-04344ca62596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "7/7 [==============================] - 14s 880ms/step - loss: 0.4545 - accuracy: 0.7990 - val_loss: 0.1562 - val_accuracy: 0.9583\n",
            "Epoch 2/10000\n",
            "7/7 [==============================] - 2s 225ms/step - loss: 0.1594 - accuracy: 0.9613 - val_loss: 0.0930 - val_accuracy: 0.9792\n",
            "Epoch 3/10000\n",
            "7/7 [==============================] - 2s 223ms/step - loss: 0.0864 - accuracy: 0.9794 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
            "Epoch 4/10000\n",
            "7/7 [==============================] - 2s 244ms/step - loss: 0.0610 - accuracy: 0.9845 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
            "Epoch 5/10000\n",
            "7/7 [==============================] - 2s 304ms/step - loss: 0.0460 - accuracy: 0.9897 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
            "Epoch 6/10000\n",
            "7/7 [==============================] - 2s 325ms/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 7/10000\n",
            "7/7 [==============================] - 1s 204ms/step - loss: 0.0283 - accuracy: 0.9948 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
            "Epoch 8/10000\n",
            "7/7 [==============================] - 1s 214ms/step - loss: 0.0252 - accuracy: 0.9974 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
            "Epoch 9/10000\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.0213 - accuracy: 0.9974 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "Epoch 10/10000\n",
            "7/7 [==============================] - 1s 211ms/step - loss: 0.0235 - accuracy: 0.9897 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 11/10000\n",
            "7/7 [==============================] - 1s 216ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 12/10000\n",
            "7/7 [==============================] - 2s 229ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 13/10000\n",
            "7/7 [==============================] - 2s 240ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 14/10000\n",
            "7/7 [==============================] - 2s 225ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 15/10000\n",
            "7/7 [==============================] - 1s 216ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
            "Epoch 16/10000\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 17/10000\n",
            "7/7 [==============================] - 2s 232ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 18/10000\n",
            "7/7 [==============================] - 2s 228ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 19/10000\n",
            "7/7 [==============================] - 2s 224ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 20/10000\n",
            "7/7 [==============================] - 1s 213ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 21/10000\n",
            "7/7 [==============================] - 1s 212ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 22/10000\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 23/10000\n",
            "7/7 [==============================] - 2s 243ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 24/10000\n",
            "7/7 [==============================] - 2s 224ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 25/10000\n",
            "7/7 [==============================] - 1s 220ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 26/10000\n",
            "7/7 [==============================] - 1s 204ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 27/10000\n",
            "7/7 [==============================] - 1s 204ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 28/10000\n",
            "7/7 [==============================] - 1s 209ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 29/10000\n",
            "7/7 [==============================] - 1s 209ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 30/10000\n",
            "7/7 [==============================] - 1s 202ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 31/10000\n",
            "7/7 [==============================] - 1s 216ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 32/10000\n",
            "7/7 [==============================] - 2s 238ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 33/10000\n",
            "7/7 [==============================] - 2s 223ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 34/10000\n",
            "7/7 [==============================] - 1s 209ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 35/10000\n",
            "7/7 [==============================] - 1s 203ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 36/10000\n",
            "7/7 [==============================] - 1s 204ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 37/10000\n",
            "7/7 [==============================] - 1s 219ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 38/10000\n",
            "7/7 [==============================] - 1s 218ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 39/10000\n",
            "7/7 [==============================] - 1s 218ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 40/10000\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 41/10000\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 42/10000\n",
            "7/7 [==============================] - 1s 212ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 43/10000\n",
            "7/7 [==============================] - 1s 210ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 44/10000\n",
            "7/7 [==============================] - 1s 209ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 45/10000\n",
            "7/7 [==============================] - 1s 201ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9896\n",
            "Epoch 46/10000\n",
            "7/7 [==============================] - 1s 210ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 47/10000\n",
            "7/7 [==============================] - 1s 201ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 48/10000\n",
            "7/7 [==============================] - 1s 211ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 49/10000\n",
            "7/7 [==============================] - 1s 213ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 50/10000\n",
            "7/7 [==============================] - 1s 215ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 51/10000\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 7.5690e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 41.\n",
            "7/7 [==============================] - 2s 230ms/step - loss: 7.8113e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 51: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7baa09ae50>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=10000, validation_data=(x_val, y_val), callbacks = [es], batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcVDXnpQoLBR",
        "outputId": "11568822-64a3-4522-a10b-cc23c2832d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 363ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAhXnGmXoLBS"
      },
      "outputs": [],
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XztTxdN80m_I",
        "outputId": "c5fa609f-107b-4883-de3f-ab7c68f738b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.80      0.88        61\n",
            "           1       0.83      0.98      0.90        60\n",
            "\n",
            "    accuracy                           0.89       121\n",
            "   macro avg       0.91      0.89      0.89       121\n",
            "weighted avg       0.91      0.89      0.89       121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZ0U7K1oLBS"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShruikbsoLBS"
      },
      "outputs": [],
      "source": [
        "# data agumentation을 진행해주고 나서 해보면 어떨까? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8MC8l07oLBS"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVgz4qm6B06p",
        "outputId": "7660755c-c237-49a3-dfec-a3ca66fa07fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "388"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oYXXvMnBaKT"
      },
      "outputs": [],
      "source": [
        "file_path = ''\n",
        "os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/normal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7FVsFiCFSGa"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 180,\n",
        "    zoom_range = 0.3,\n",
        "    zca_whitening = False,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    \n",
        ")\n",
        "\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsfEVAMKFcmy",
        "outputId": "7c10fe89-483a-4c1e-c850-6377589b4f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "13/13 [==============================] - 12s 649ms/step - loss: 0.1127 - accuracy: 0.9510 - val_loss: 0.0494 - val_accuracy: 0.9896\n",
            "Epoch 2/1000\n",
            "13/13 [==============================] - 7s 508ms/step - loss: 0.0892 - accuracy: 0.9639 - val_loss: 0.1888 - val_accuracy: 0.9375\n",
            "Epoch 3/1000\n",
            "13/13 [==============================] - 8s 623ms/step - loss: 0.0944 - accuracy: 0.9665 - val_loss: 0.0907 - val_accuracy: 0.9688\n",
            "Epoch 4/1000\n",
            "13/13 [==============================] - 7s 523ms/step - loss: 0.0692 - accuracy: 0.9742 - val_loss: 0.0227 - val_accuracy: 0.9896\n",
            "Epoch 5/1000\n",
            "13/13 [==============================] - 8s 626ms/step - loss: 0.0588 - accuracy: 0.9768 - val_loss: 0.0264 - val_accuracy: 0.9896\n",
            "Epoch 6/1000\n",
            "13/13 [==============================] - 7s 509ms/step - loss: 0.0405 - accuracy: 0.9845 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 7/1000\n",
            "13/13 [==============================] - 8s 573ms/step - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 8/1000\n",
            "13/13 [==============================] - 7s 548ms/step - loss: 0.0604 - accuracy: 0.9820 - val_loss: 0.0724 - val_accuracy: 0.9583\n",
            "Epoch 9/1000\n",
            "13/13 [==============================] - 7s 612ms/step - loss: 0.0588 - accuracy: 0.9768 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 10/1000\n",
            "13/13 [==============================] - 8s 612ms/step - loss: 0.0462 - accuracy: 0.9820 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 11/1000\n",
            "13/13 [==============================] - 7s 512ms/step - loss: 0.0389 - accuracy: 0.9871 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "13/13 [==============================] - 8s 633ms/step - loss: 0.0451 - accuracy: 0.9845 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "13/13 [==============================] - 7s 526ms/step - loss: 0.0405 - accuracy: 0.9897 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 14/1000\n",
            "13/13 [==============================] - 8s 631ms/step - loss: 0.0635 - accuracy: 0.9820 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 15/1000\n",
            "13/13 [==============================] - 7s 493ms/step - loss: 0.0467 - accuracy: 0.9820 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
            "Epoch 16/1000\n",
            "13/13 [==============================] - 8s 618ms/step - loss: 0.0343 - accuracy: 0.9871 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "13/13 [==============================] - 7s 510ms/step - loss: 0.0341 - accuracy: 0.9948 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 18/1000\n",
            "13/13 [==============================] - 7s 496ms/step - loss: 0.0257 - accuracy: 0.9897 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "13/13 [==============================] - 8s 627ms/step - loss: 0.0380 - accuracy: 0.9820 - val_loss: 0.0215 - val_accuracy: 0.9896\n",
            "Epoch 20/1000\n",
            "13/13 [==============================] - 7s 517ms/step - loss: 0.0432 - accuracy: 0.9897 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "13/13 [==============================] - 8s 613ms/step - loss: 0.0260 - accuracy: 0.9897 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 22/1000\n",
            "13/13 [==============================] - 7s 533ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 23/1000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9871Restoring model weights from the end of the best epoch: 13.\n",
            "13/13 [==============================] - 8s 564ms/step - loss: 0.0439 - accuracy: 0.9871 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 23: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b9021e5b0>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(datagen.flow(x_train, y_train), epochs = 1000, validation_data = (x_val, y_val), verbose = 1, callbacks = [es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V49EwrfMSZc",
        "outputId": "d3e851b5-fbf3-42b4-a714-2a56be38a8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 81ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oDs6Hn4MWGp"
      },
      "outputs": [],
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccg0bnPYMWx5",
        "outputId": "871a465c-abd6-4481-82c7-023e0b025c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.74      0.84        61\n",
            "           1       0.79      0.98      0.87        60\n",
            "\n",
            "    accuracy                           0.86       121\n",
            "   macro avg       0.88      0.86      0.86       121\n",
            "weighted avg       0.88      0.86      0.86       121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "# data agumentation을 잘 해줬는지 모르겠을 뿐더라, 일단은 여기까지 인 것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRqzBw8eccwj"
      },
      "source": [
        "### (5) 모델3\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtNd8u5RoNJo"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-m0XD-bLBOO"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_val = np.array(x_val)\n",
        "x_test = np.array(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sOUUht3MlpE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0wel3kXMyDm",
        "outputId": "9cb58a23-5529-4ff8-f769-5dd47de77f94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "238"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ],
      "source": [
        "len(base_model.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {
        "id": "tSyXgL3JIhMu"
      },
      "outputs": [],
      "source": [
        "# 나는 EfficientNetB0을 pretrained model로 가져올게요\n",
        "base_model = tf.keras.applications.VGG16(include_top = False, # 그림으로 보면 주로 아래로 쌓이는데 왜 include top일까? \n",
        "                                          weights ='imagenet', # imagenet 바탕으로 미리 학습된 것 (include_top을 True로 해줬을 때, \n",
        "                                          # 마지막 레이어가 1000으로 나누어준다는 사실을 알 수 있다.)\n",
        "                                          input_shape = (280, 280, 3))\n",
        "\n",
        "# pretrained 된 모델 (output 빼고) freeze -> 가중치 가져오겠단 말\n",
        "for idx, layer in enumerate(base_model.layers) :\n",
        "    if idx < 225 :\n",
        "        layer.trainable = False # 가중치는 가지고\n",
        "    else :\n",
        "        layer.trainable = True\n",
        "\n",
        "# Functional API를 이용한 엮기\n",
        "\n",
        "il = base_model.output\n",
        "cl = layers.GlobalAveragePooling2D()(il)\n",
        "bl = layers.BatchNormalization()(cl)\n",
        "hl = layers.Dense(256, activation='relu')(bl)\n",
        "hl = layers.Dropout(0.3)(hl)\n",
        "ol = layers.Dense(1, activation='sigmoid')(hl)\n",
        "\n",
        "# 시작과 끝 엮기\n",
        "# 여기서 뭣모르고 input을 il했다가는 pretrained 다 날리고 layer 층 5개만 쌓인다.\n",
        "# 반드시 inputs = base_model.input\n",
        "model = models.Model(base_model.input, ol)\n",
        "\n",
        "# 컴파일\n",
        "model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "id": "TOgvx9ErR2u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4723d3e4-37f1-4bbc-a224-9d875dfe5b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 5s 561ms/step\n",
            "Epoch 1/10000\n",
            "12/12 [==============================] - 11s 598ms/step - loss: 0.6771 - accuracy: 0.7592 - val_loss: 1.8915 - val_accuracy: 0.6042\n",
            "Epoch 2/10000\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 0.2689 - accuracy: 0.9084 - val_loss: 0.6679 - val_accuracy: 0.7708\n",
            "Epoch 3/10000\n",
            "12/12 [==============================] - 4s 320ms/step - loss: 0.1675 - accuracy: 0.9424 - val_loss: 0.7314 - val_accuracy: 0.7708\n",
            "Epoch 4/10000\n",
            "12/12 [==============================] - 4s 334ms/step - loss: 0.0899 - accuracy: 0.9791 - val_loss: 0.6022 - val_accuracy: 0.7812\n",
            "Epoch 5/10000\n",
            "12/12 [==============================] - 4s 337ms/step - loss: 0.0424 - accuracy: 0.9974 - val_loss: 0.5566 - val_accuracy: 0.8333\n",
            "Epoch 6/10000\n",
            "12/12 [==============================] - 4s 321ms/step - loss: 0.0357 - accuracy: 0.9948 - val_loss: 0.6741 - val_accuracy: 0.8021\n",
            "Epoch 7/10000\n",
            "12/12 [==============================] - 4s 313ms/step - loss: 0.0312 - accuracy: 0.9974 - val_loss: 0.6037 - val_accuracy: 0.8021\n",
            "Epoch 8/10000\n",
            "12/12 [==============================] - 4s 359ms/step - loss: 0.0286 - accuracy: 0.9948 - val_loss: 0.6241 - val_accuracy: 0.7917\n",
            "Epoch 9/10000\n",
            "12/12 [==============================] - 4s 306ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.8125\n",
            "Epoch 10/10000\n",
            "12/12 [==============================] - 4s 366ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.8125\n",
            "4/4 [==============================] - 1s 223ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.48      0.57        61\n",
            "           1       0.60      0.82      0.70        60\n",
            "\n",
            "    accuracy                           0.64       121\n",
            "   macro avg       0.66      0.65      0.63       121\n",
            "weighted avg       0.67      0.64      0.63       121\n",
            "\n",
            "0.6446280991735537\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "model.fit(x_train, y_train, epochs=10000, validation_data=(x_val, y_val), callbacks = [es], batch_size = 32)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.where(y_pred > 0.5, 1 ,0)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "dxn_L6-HTvaE"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 369,
      "metadata": {
        "id": "uT-63eSfR7kL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "0355397d-fea1-48d3-f7f7-c4e8aca0b10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "12/12 [==============================] - 4s 370ms/step - loss: 0.0372 - accuracy: 0.9974 - val_loss: 0.6161 - val_accuracy: 0.7917\n",
            "Epoch 2/10000\n",
            "12/12 [==============================] - 4s 301ms/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.5837 - val_accuracy: 0.7917\n",
            "Epoch 3/10000\n",
            "12/12 [==============================] - 4s 302ms/step - loss: 0.0355 - accuracy: 0.9948 - val_loss: 0.5916 - val_accuracy: 0.8021\n",
            "Epoch 4/10000\n",
            "12/12 [==============================] - 4s 313ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.5786 - val_accuracy: 0.8333\n",
            "Epoch 5/10000\n",
            "12/12 [==============================] - 4s 308ms/step - loss: 0.0246 - accuracy: 0.9948 - val_loss: 0.7043 - val_accuracy: 0.7917\n",
            "Epoch 6/10000\n",
            "12/12 [==============================] - 4s 312ms/step - loss: 0.0163 - accuracy: 0.9974 - val_loss: 0.6261 - val_accuracy: 0.8125\n",
            "Epoch 7/10000\n",
            "12/12 [==============================] - 4s 378ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5677 - val_accuracy: 0.8125\n",
            "Epoch 8/10000\n",
            "12/12 [==============================] - 4s 368ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.8229\n",
            "Epoch 9/10000\n",
            " 5/12 [===========>..................] - ETA: 1s - loss: 0.0179 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-369-889135d9cc57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=10000, validation_data=(x_val, y_val), callbacks = [es], batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "r7rRo642U9Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1 ,0)"
      ],
      "metadata": {
        "id": "DKq2Qd7jU9iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "625NMNMcU90o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "D4ErWqUVU98V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TMH_KGTU-By"
      },
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aV1GOjiHU-Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zgVkXLHoNJo"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTlUNbkhoNJo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4GYo0dboNJo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZV9zbsroNJo"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc9UmjZ0oNJo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP-p0_y9oNJo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxUpfhJ1xXle"
      },
      "source": [
        "## 4.모델링 II\n",
        "* **세부요구사항**\n",
        "    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n",
        "        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n",
        "            - ImageDataGenerator를 사용합니다.\n",
        "        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n",
        "            - VGG16(이미지넷)을 사용해 봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouCRBdKPxCut"
      },
      "source": [
        "### (1) Data Augmentation\n",
        "- **세부요구사항**\n",
        "    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n",
        "    * Keras의 ImageDataGenerator를 이용\n",
        "        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
        "\n",
        "    * image generator를 이용하여 학습\n",
        "        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe6yjs8F7Zox"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYae9YFt8Q03"
      },
      "outputs": [],
      "source": [
        "img_size = 280 ## 사이즈 조정 가능\n",
        "\n",
        "train_path = dataset_path+'Car_Images_train/'\n",
        "valid_path = dataset_path+'Car_Images_valid/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4jIyTGfXD_"
      },
      "source": [
        "#### 1) ImageGenerator 생성\n",
        "* ImageDataGenerator 함수 사용\n",
        "    * 주요 옵션\n",
        "        * rotation_range: 무작위 회전을 적용할 각도 범위\n",
        "        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n",
        "        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n",
        "        * vertical_flip: 무작위 상하반전을 적용할지 여부\n",
        "        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "LKPPSwYn7Zrj",
        "outputId": "ad862dfd-d07e-46f0-8ef8-b56b8cf297f9"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-911ce1113591>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    train_datagen =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "train_datagen = \n",
        "\n",
        "valid_datagen = \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKwSYYkufanb"
      },
      "source": [
        "#### 2) 경로로 부터 이미지 불러 올 준비\n",
        "* .flow_from_directory 이용\n",
        "    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n",
        "    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n",
        "    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bwvQ4hHSCwY"
      },
      "outputs": [],
      "source": [
        "train_generator = \n",
        "\n",
        "valid_generator = \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4RPCjU5f662"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 train_generator 이용. \n",
        "    - validation_data = valid_generator 지정\n",
        "    - Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVMLsXw6f663"
      },
      "source": [
        "* 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W7rqgH1f663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw2_G7zdf663"
      },
      "source": [
        "* 학습\n",
        "    * EarlyStopping 설정하기\n",
        "    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m5mRE9Nf663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCWzBSYqf663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdKiY1uIf663"
      },
      "source": [
        "#### 4) 성능 평가\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qjnvt0lf663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBl4Do0af663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1iv22vSxXle"
      },
      "source": [
        "### (2) Transfer Learning\n",
        "- **세부요구사항**\n",
        "    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n",
        "        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n",
        "        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n",
        "    * VGG16 함수로 부터 base_model 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnS12YhDxXle"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3kyvCwIiAfi"
      },
      "source": [
        "#### 1) VGG16 불러와서 저장하기\n",
        "* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n",
        "* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFf3IxbBGe9B"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(                 )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-JjBLZZiIxA"
      },
      "source": [
        "#### 2) VGG16과 연결한 구조 설계\n",
        "* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg4KhHQ8xXlf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V5heiDxxXlf"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "    - 데이터\n",
        "        * Image Generator를 연결하거나\n",
        "        * 기존 train, validation 셋을 이용해도 됩니다.\n",
        "        - Early Stopping을 반드시 사용하세요.\n",
        "        - 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtqQIS-HxXlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zg0L88Gwf4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbhiWcS5i735"
      },
      "source": [
        "#### 4) 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik4AFzCQi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkkSsyMoi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGuQMUJNxXSy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}